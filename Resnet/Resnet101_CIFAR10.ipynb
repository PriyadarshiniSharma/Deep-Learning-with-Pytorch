{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vWv19wRzlNyC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Uktb-DwwmFQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de530d28-6ec1-4d73-d78d-1aebb9d02c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_mY37zSgosxq"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n",
        "\n",
        "from ResNet import ResNet, ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wLbpRoQSlNyE"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BLh1pq6SlNyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffc5a6ed-cedf-484b-8b7f-c40eec3172ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:01<00:00, 101430070.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test, batch_size=128,shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "guCzw8Z6lNyE"
      },
      "outputs": [],
      "source": [
        "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mzEXGxyWlNyF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ResNet101(3).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ecRopn2elNyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e95547-f115-4f10-df70-ec153b1f303f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss [1, 100](epoch, minibatch):  6.9983795499801635\n",
            "Loss [1, 200](epoch, minibatch):  3.43063227891922\n",
            "Loss [1, 300](epoch, minibatch):  2.6868314385414123\n",
            "Loss [2, 100](epoch, minibatch):  2.34351522564888\n",
            "Loss [2, 200](epoch, minibatch):  2.189417153596878\n",
            "Loss [2, 300](epoch, minibatch):  2.028717914819717\n",
            "Loss [3, 100](epoch, minibatch):  1.9946791803836823\n",
            "Loss [3, 200](epoch, minibatch):  1.943064739704132\n",
            "Loss [3, 300](epoch, minibatch):  1.9243985247611999\n",
            "Loss [4, 100](epoch, minibatch):  1.9229141187667846\n",
            "Loss [4, 200](epoch, minibatch):  1.8872440791130065\n",
            "Loss [4, 300](epoch, minibatch):  1.8746490454673768\n",
            "Loss [5, 100](epoch, minibatch):  1.8788133943080902\n",
            "Loss [5, 200](epoch, minibatch):  1.8546157193183899\n",
            "Loss [5, 300](epoch, minibatch):  1.8262171459197998\n",
            "Loss [6, 100](epoch, minibatch):  1.8502129077911378\n",
            "Loss [6, 200](epoch, minibatch):  1.8054807829856871\n",
            "Loss [6, 300](epoch, minibatch):  1.7503284955024718\n",
            "Loss [7, 100](epoch, minibatch):  1.7242645370960235\n",
            "Loss [7, 200](epoch, minibatch):  1.7094747912883759\n",
            "Loss [7, 300](epoch, minibatch):  1.6908090102672577\n",
            "Loss [8, 100](epoch, minibatch):  1.6865310275554657\n",
            "Loss [8, 200](epoch, minibatch):  1.6566419315338134\n",
            "Loss [8, 300](epoch, minibatch):  1.6378576731681824\n",
            "Loss [9, 100](epoch, minibatch):  1.6481906032562257\n",
            "Loss [9, 200](epoch, minibatch):  1.6153271317481994\n",
            "Loss [9, 300](epoch, minibatch):  1.5969178664684296\n",
            "Loss [10, 100](epoch, minibatch):  1.5809977495670318\n",
            "Loss [10, 200](epoch, minibatch):  1.5490937101840974\n",
            "Loss [10, 300](epoch, minibatch):  1.5311645901203155\n",
            "Loss [11, 100](epoch, minibatch):  1.5128006291389466\n",
            "Loss [11, 200](epoch, minibatch):  1.489193961620331\n",
            "Loss [11, 300](epoch, minibatch):  1.4684587717056274\n",
            "Loss [12, 100](epoch, minibatch):  1.438629994392395\n",
            "Loss [12, 200](epoch, minibatch):  1.433177092075348\n",
            "Loss [12, 300](epoch, minibatch):  1.4195097661018372\n",
            "Loss [13, 100](epoch, minibatch):  1.4099477016925812\n",
            "Loss [13, 200](epoch, minibatch):  1.3850202333927155\n",
            "Loss [13, 300](epoch, minibatch):  1.375212812423706\n",
            "Loss [14, 100](epoch, minibatch):  1.3620133256912232\n",
            "Loss [14, 200](epoch, minibatch):  1.3650248670578002\n",
            "Loss [14, 300](epoch, minibatch):  1.3402962982654572\n",
            "Loss [15, 100](epoch, minibatch):  1.3310300087928773\n",
            "Loss [15, 200](epoch, minibatch):  1.3239069950580598\n",
            "Loss [15, 300](epoch, minibatch):  1.3098393404483795\n",
            "Loss [16, 100](epoch, minibatch):  1.3111988484859467\n",
            "Loss [16, 200](epoch, minibatch):  1.2962352228164673\n",
            "Loss [16, 300](epoch, minibatch):  1.2802681183815003\n",
            "Loss [17, 100](epoch, minibatch):  1.2721771335601806\n",
            "Loss [17, 200](epoch, minibatch):  1.2958608198165893\n",
            "Loss [17, 300](epoch, minibatch):  1.4188671052455901\n",
            "Loss [18, 100](epoch, minibatch):  1.3575453919172287\n",
            "Loss [18, 200](epoch, minibatch):  1.2912686824798585\n",
            "Loss [18, 300](epoch, minibatch):  1.277776561975479\n",
            "Loss [19, 100](epoch, minibatch):  1.2639141023159026\n",
            "Loss [19, 200](epoch, minibatch):  1.2469904828071594\n",
            "Loss [19, 300](epoch, minibatch):  1.2220043855905534\n",
            "Loss [20, 100](epoch, minibatch):  1.2251492702960969\n",
            "Loss [20, 200](epoch, minibatch):  1.1872486317157744\n",
            "Loss [20, 300](epoch, minibatch):  1.1866203951835632\n",
            "Loss [21, 100](epoch, minibatch):  1.1622350323200226\n",
            "Loss [21, 200](epoch, minibatch):  1.1626694297790527\n",
            "Loss [21, 300](epoch, minibatch):  1.1645304375886918\n",
            "Loss [22, 100](epoch, minibatch):  1.1299729025363923\n",
            "Loss [22, 200](epoch, minibatch):  1.12444678068161\n",
            "Loss [22, 300](epoch, minibatch):  1.1281203043460846\n",
            "Loss [23, 100](epoch, minibatch):  1.1104919373989106\n",
            "Loss [23, 200](epoch, minibatch):  1.1271846199035644\n",
            "Loss [23, 300](epoch, minibatch):  1.0998668718338012\n",
            "Loss [24, 100](epoch, minibatch):  1.1338378977775574\n",
            "Loss [24, 200](epoch, minibatch):  1.0889727932214737\n",
            "Loss [24, 300](epoch, minibatch):  1.0886935305595398\n",
            "Loss [25, 100](epoch, minibatch):  1.0570271027088165\n",
            "Loss [25, 200](epoch, minibatch):  1.0496737587451934\n",
            "Loss [25, 300](epoch, minibatch):  1.0474942862987517\n",
            "Loss [26, 100](epoch, minibatch):  1.0296355271339417\n",
            "Loss [26, 200](epoch, minibatch):  1.0405364668369292\n",
            "Loss [26, 300](epoch, minibatch):  1.004643778204918\n",
            "Loss [27, 100](epoch, minibatch):  1.0078394669294357\n",
            "Loss [27, 200](epoch, minibatch):  0.9887868696451187\n",
            "Loss [27, 300](epoch, minibatch):  1.0097190189361571\n",
            "Loss [28, 100](epoch, minibatch):  0.9933873218297958\n",
            "Loss [28, 200](epoch, minibatch):  1.0023662465810776\n",
            "Loss [28, 300](epoch, minibatch):  1.005421050786972\n",
            "Loss [29, 100](epoch, minibatch):  0.9504604583978653\n",
            "Loss [29, 200](epoch, minibatch):  0.9597278952598571\n",
            "Loss [29, 300](epoch, minibatch):  0.9764379811286926\n",
            "Loss [30, 100](epoch, minibatch):  0.9428418362140656\n",
            "Loss [30, 200](epoch, minibatch):  1.021733704805374\n",
            "Loss [30, 300](epoch, minibatch):  1.4375421738624572\n",
            "Loss [31, 100](epoch, minibatch):  1.0896883803606032\n",
            "Loss [31, 200](epoch, minibatch):  1.0474884814023973\n",
            "Loss [31, 300](epoch, minibatch):  1.0318921494483948\n",
            "Loss [32, 100](epoch, minibatch):  0.9659537589550018\n",
            "Loss [32, 200](epoch, minibatch):  0.9734430932998657\n",
            "Loss [32, 300](epoch, minibatch):  0.9614727169275283\n",
            "Loss [33, 100](epoch, minibatch):  0.9537268429994583\n",
            "Loss [33, 200](epoch, minibatch):  0.9353218877315521\n",
            "Loss [33, 300](epoch, minibatch):  0.9275653570890426\n",
            "Loss [34, 100](epoch, minibatch):  0.903404769897461\n",
            "Loss [34, 200](epoch, minibatch):  0.8935340249538422\n",
            "Loss [34, 300](epoch, minibatch):  0.8680960762500763\n",
            "Loss [35, 100](epoch, minibatch):  0.8658104085922241\n",
            "Loss [35, 200](epoch, minibatch):  0.8667105025053025\n",
            "Loss [35, 300](epoch, minibatch):  0.8581280183792114\n",
            "Loss [36, 100](epoch, minibatch):  0.8505049443244934\n",
            "Loss [36, 200](epoch, minibatch):  0.848114070892334\n",
            "Loss [36, 300](epoch, minibatch):  0.8506770807504654\n",
            "Loss [37, 100](epoch, minibatch):  0.8357572811841965\n",
            "Loss [37, 200](epoch, minibatch):  0.8179197239875794\n",
            "Loss [37, 300](epoch, minibatch):  0.8401108855009078\n",
            "Loss [38, 100](epoch, minibatch):  0.8106173539161682\n",
            "Loss [38, 200](epoch, minibatch):  0.81848901450634\n",
            "Loss [38, 300](epoch, minibatch):  0.8062350296974182\n",
            "Loss [39, 100](epoch, minibatch):  0.805040271282196\n",
            "Loss [39, 200](epoch, minibatch):  0.7948788034915925\n",
            "Loss [39, 300](epoch, minibatch):  0.8193837243318558\n",
            "Loss [40, 100](epoch, minibatch):  0.8037350118160248\n",
            "Loss [40, 200](epoch, minibatch):  0.7895449429750443\n",
            "Loss [40, 300](epoch, minibatch):  0.7745606476068496\n",
            "Loss [41, 100](epoch, minibatch):  0.7722847437858582\n",
            "Loss [41, 200](epoch, minibatch):  0.8195813006162643\n",
            "Loss [41, 300](epoch, minibatch):  0.779886885881424\n",
            "Loss [42, 100](epoch, minibatch):  0.7677110677957535\n",
            "Loss [42, 200](epoch, minibatch):  0.7555462265014649\n",
            "Loss [42, 300](epoch, minibatch):  0.7720209747552872\n",
            "Loss [43, 100](epoch, minibatch):  0.7726264268159866\n",
            "Loss [43, 200](epoch, minibatch):  0.7469117784500122\n",
            "Loss [43, 300](epoch, minibatch):  0.7512517493963241\n",
            "Loss [44, 100](epoch, minibatch):  0.7403706356883049\n",
            "Loss [44, 200](epoch, minibatch):  0.7358575940132142\n",
            "Loss [44, 300](epoch, minibatch):  0.7419998079538346\n",
            "Loss [45, 100](epoch, minibatch):  0.8195352011919022\n",
            "Loss [45, 200](epoch, minibatch):  0.8109974312782288\n",
            "Loss [45, 300](epoch, minibatch):  0.763433690071106\n",
            "Loss [46, 100](epoch, minibatch):  0.7086197739839554\n",
            "Loss [46, 200](epoch, minibatch):  0.7306561732292175\n",
            "Loss [46, 300](epoch, minibatch):  0.7172330194711685\n",
            "Loss [47, 100](epoch, minibatch):  0.7102757179737091\n",
            "Loss [47, 200](epoch, minibatch):  0.6989358019828796\n",
            "Loss [47, 300](epoch, minibatch):  0.6891200560331344\n",
            "Loss [48, 100](epoch, minibatch):  0.6777697351574897\n",
            "Loss [48, 200](epoch, minibatch):  0.6797919324040413\n",
            "Loss [48, 300](epoch, minibatch):  0.656019578576088\n",
            "Loss [49, 100](epoch, minibatch):  0.6801321125030517\n",
            "Loss [49, 200](epoch, minibatch):  0.6745017978549004\n",
            "Loss [49, 300](epoch, minibatch):  0.6803929531574249\n",
            "Loss [50, 100](epoch, minibatch):  0.6578326535224914\n",
            "Loss [50, 200](epoch, minibatch):  0.6601994627714157\n",
            "Loss [50, 300](epoch, minibatch):  0.6681820493936539\n",
            "Loss [51, 100](epoch, minibatch):  0.6674988707900047\n",
            "Loss [51, 200](epoch, minibatch):  0.6426766419410705\n",
            "Loss [51, 300](epoch, minibatch):  0.6577823743224144\n",
            "Loss [52, 100](epoch, minibatch):  0.6398857617378235\n",
            "Loss [52, 200](epoch, minibatch):  0.6420306581258773\n",
            "Loss [52, 300](epoch, minibatch):  0.6417034918069839\n",
            "Loss [53, 100](epoch, minibatch):  0.6181650227308273\n",
            "Loss [53, 200](epoch, minibatch):  0.6163686302304268\n",
            "Loss [53, 300](epoch, minibatch):  0.6340082323551178\n",
            "Loss [54, 100](epoch, minibatch):  0.6147315213084221\n",
            "Loss [54, 200](epoch, minibatch):  0.6233598178625107\n",
            "Loss [54, 300](epoch, minibatch):  0.6257577174901963\n",
            "Loss [55, 100](epoch, minibatch):  0.6197878986597061\n",
            "Loss [55, 200](epoch, minibatch):  0.6115734961628914\n",
            "Loss [55, 300](epoch, minibatch):  0.6286799329519271\n",
            "Loss [56, 100](epoch, minibatch):  0.591333590745926\n",
            "Loss [56, 200](epoch, minibatch):  0.5985582715272904\n",
            "Loss [56, 300](epoch, minibatch):  0.610844443142414\n",
            "Loss [57, 100](epoch, minibatch):  0.5996804523468018\n",
            "Loss [57, 200](epoch, minibatch):  0.5878161144256592\n",
            "Loss [57, 300](epoch, minibatch):  0.5904057630896569\n",
            "Loss [58, 100](epoch, minibatch):  0.5829785293340684\n",
            "Loss [58, 200](epoch, minibatch):  0.5853916722536087\n",
            "Loss [58, 300](epoch, minibatch):  0.6008851963281632\n",
            "Loss [59, 100](epoch, minibatch):  0.5704396256804466\n",
            "Loss [59, 200](epoch, minibatch):  0.5817970737814904\n",
            "Loss [59, 300](epoch, minibatch):  0.6006554171442986\n",
            "Loss [60, 100](epoch, minibatch):  0.5633589014410972\n",
            "Loss [60, 200](epoch, minibatch):  0.5677698826789856\n",
            "Loss [60, 300](epoch, minibatch):  0.5946858337521553\n",
            "Loss [61, 100](epoch, minibatch):  0.5733803975582122\n",
            "Loss [61, 200](epoch, minibatch):  0.5528019890189171\n",
            "Loss [61, 300](epoch, minibatch):  0.5750673517584801\n",
            "Loss [62, 100](epoch, minibatch):  0.5643032413721084\n",
            "Loss [62, 200](epoch, minibatch):  0.5495411896705628\n",
            "Loss [62, 300](epoch, minibatch):  0.5874888464808464\n",
            "Loss [63, 100](epoch, minibatch):  0.57704441010952\n",
            "Loss [63, 200](epoch, minibatch):  0.5670481643080711\n",
            "Loss [63, 300](epoch, minibatch):  0.5718747547268868\n",
            "Loss [64, 100](epoch, minibatch):  0.547606631219387\n",
            "Loss [64, 200](epoch, minibatch):  0.5395768710970879\n",
            "Loss [64, 300](epoch, minibatch):  0.5570298597216606\n",
            "Loss [65, 100](epoch, minibatch):  0.5500346201658249\n",
            "Loss [65, 200](epoch, minibatch):  0.5372493690252305\n",
            "Loss [65, 300](epoch, minibatch):  0.5580257269740104\n",
            "Loss [66, 100](epoch, minibatch):  0.5309275671839714\n",
            "Loss [66, 200](epoch, minibatch):  0.5307791355252266\n",
            "Loss [66, 300](epoch, minibatch):  0.5451214799284935\n",
            "Loss [67, 100](epoch, minibatch):  0.5142997550964356\n",
            "Loss [67, 200](epoch, minibatch):  0.5422490027546882\n",
            "Loss [67, 300](epoch, minibatch):  0.5386299973726273\n",
            "Loss [68, 100](epoch, minibatch):  0.5355253514647483\n",
            "Loss [68, 200](epoch, minibatch):  0.5170803159475327\n",
            "Loss [68, 300](epoch, minibatch):  0.5318678429722786\n",
            "Loss [69, 100](epoch, minibatch):  0.5209760296344758\n",
            "Loss [69, 200](epoch, minibatch):  0.5203809854388237\n",
            "Loss [69, 300](epoch, minibatch):  0.5177020046114922\n",
            "Loss [70, 100](epoch, minibatch):  0.5127561622858048\n",
            "Loss [70, 200](epoch, minibatch):  0.5140496420860291\n",
            "Loss [70, 300](epoch, minibatch):  0.5064743211865426\n",
            "Loss [71, 100](epoch, minibatch):  0.5261956897377967\n",
            "Loss [71, 200](epoch, minibatch):  0.5031635567545891\n",
            "Loss [71, 300](epoch, minibatch):  0.5203497388958931\n",
            "Loss [72, 100](epoch, minibatch):  0.49265503615140915\n",
            "Loss [72, 200](epoch, minibatch):  0.4986958557367325\n",
            "Loss [72, 300](epoch, minibatch):  0.5029798591136933\n",
            "Loss [73, 100](epoch, minibatch):  0.4923164176940918\n",
            "Loss [73, 200](epoch, minibatch):  0.49802658170461656\n",
            "Loss [73, 300](epoch, minibatch):  0.5074251505732537\n",
            "Loss [74, 100](epoch, minibatch):  0.49053321659564975\n",
            "Loss [74, 200](epoch, minibatch):  0.5016406691074371\n",
            "Loss [74, 300](epoch, minibatch):  0.506693666279316\n",
            "Loss [75, 100](epoch, minibatch):  0.49374434888362884\n",
            "Loss [75, 200](epoch, minibatch):  0.5067057234048843\n",
            "Loss [75, 300](epoch, minibatch):  0.48718385100364686\n",
            "Loss [76, 100](epoch, minibatch):  0.4847361996769905\n",
            "Loss [76, 200](epoch, minibatch):  0.48156808346509933\n",
            "Loss [76, 300](epoch, minibatch):  0.49090177282691\n",
            "Loss [77, 100](epoch, minibatch):  0.4653179323673248\n",
            "Loss [77, 200](epoch, minibatch):  0.4704501584172249\n",
            "Loss [77, 300](epoch, minibatch):  0.49585506796836853\n",
            "Loss [78, 100](epoch, minibatch):  0.46415785238146784\n",
            "Loss [78, 200](epoch, minibatch):  0.47872972309589384\n",
            "Loss [78, 300](epoch, minibatch):  0.48757142424583433\n",
            "Loss [79, 100](epoch, minibatch):  0.45737267583608626\n",
            "Loss [79, 200](epoch, minibatch):  0.46067551523447037\n",
            "Loss [79, 300](epoch, minibatch):  0.47383534997701643\n",
            "Loss [80, 100](epoch, minibatch):  0.46714653849601745\n",
            "Loss [80, 200](epoch, minibatch):  0.4628117215633392\n",
            "Loss [80, 300](epoch, minibatch):  0.4807684364914894\n",
            "Loss [81, 100](epoch, minibatch):  0.4521406164765358\n",
            "Loss [81, 200](epoch, minibatch):  0.46313412129879\n",
            "Loss [81, 300](epoch, minibatch):  0.47593362361192704\n",
            "Loss [82, 100](epoch, minibatch):  0.4509156534075737\n",
            "Loss [82, 200](epoch, minibatch):  0.4579740962386131\n",
            "Loss [82, 300](epoch, minibatch):  0.46420088738203047\n",
            "Loss [83, 100](epoch, minibatch):  0.45539340257644656\n",
            "Loss [83, 200](epoch, minibatch):  0.45546282947063443\n",
            "Loss [83, 300](epoch, minibatch):  0.46054095089435576\n",
            "Loss [84, 100](epoch, minibatch):  0.4360914698243141\n",
            "Loss [84, 200](epoch, minibatch):  0.44368520319461824\n",
            "Loss [84, 300](epoch, minibatch):  0.460866864323616\n",
            "Loss [85, 100](epoch, minibatch):  0.4587948051095009\n",
            "Loss [85, 200](epoch, minibatch):  0.46054991602897644\n",
            "Loss [85, 300](epoch, minibatch):  0.45020519822835925\n",
            "Loss [86, 100](epoch, minibatch):  0.4509481006860733\n",
            "Loss [86, 200](epoch, minibatch):  0.4550776255130768\n",
            "Loss [86, 300](epoch, minibatch):  0.44629544883966443\n",
            "Loss [87, 100](epoch, minibatch):  0.4356223785877228\n",
            "Loss [87, 200](epoch, minibatch):  0.4230224135518074\n",
            "Loss [87, 300](epoch, minibatch):  0.4548139253258705\n",
            "Loss [88, 100](epoch, minibatch):  0.4253796248137951\n",
            "Loss [88, 200](epoch, minibatch):  0.42653982251882555\n",
            "Loss [88, 300](epoch, minibatch):  0.4506459498405457\n",
            "Loss [89, 100](epoch, minibatch):  0.4351797352731228\n",
            "Loss [89, 200](epoch, minibatch):  0.43338429778814314\n",
            "Loss [89, 300](epoch, minibatch):  0.4325253713130951\n",
            "Loss [90, 100](epoch, minibatch):  0.39964773803949355\n",
            "Loss [90, 200](epoch, minibatch):  0.43060100823640823\n",
            "Loss [90, 300](epoch, minibatch):  0.45769510209560393\n",
            "Loss [91, 100](epoch, minibatch):  0.42785693526268004\n",
            "Loss [91, 200](epoch, minibatch):  0.41873271942138673\n",
            "Loss [91, 300](epoch, minibatch):  0.4197122290730476\n",
            "Loss [92, 100](epoch, minibatch):  0.40768801659345627\n",
            "Loss [92, 200](epoch, minibatch):  0.4246831278502941\n",
            "Loss [92, 300](epoch, minibatch):  0.4257234826683998\n",
            "Loss [93, 100](epoch, minibatch):  0.42417324021458624\n",
            "Loss [93, 200](epoch, minibatch):  0.43771094679832456\n",
            "Loss [93, 300](epoch, minibatch):  0.4116471894085407\n",
            "Loss [94, 100](epoch, minibatch):  0.40754967376589774\n",
            "Loss [94, 200](epoch, minibatch):  0.4192144000530243\n",
            "Loss [94, 300](epoch, minibatch):  0.4320470640063286\n",
            "Loss [95, 100](epoch, minibatch):  0.40289605751633645\n",
            "Loss [95, 200](epoch, minibatch):  0.4266053572297096\n",
            "Loss [95, 300](epoch, minibatch):  0.426305892765522\n",
            "Loss [96, 100](epoch, minibatch):  0.40117313235998153\n",
            "Loss [96, 200](epoch, minibatch):  0.41872202351689336\n",
            "Loss [96, 300](epoch, minibatch):  0.41533143430948255\n",
            "Loss [97, 100](epoch, minibatch):  0.4136146754026413\n",
            "Loss [97, 200](epoch, minibatch):  0.42568994671106336\n",
            "Loss [97, 300](epoch, minibatch):  0.40809153974056245\n",
            "Loss [98, 100](epoch, minibatch):  0.4101807677745819\n",
            "Loss [98, 200](epoch, minibatch):  0.4067677173018456\n",
            "Loss [98, 300](epoch, minibatch):  0.42840194135904314\n",
            "Loss [99, 100](epoch, minibatch):  0.3990762957930565\n",
            "Loss [99, 200](epoch, minibatch):  0.4049002707004547\n",
            "Loss [99, 300](epoch, minibatch):  0.4093237161636353\n",
            "Loss [100, 100](epoch, minibatch):  0.40743389680981634\n",
            "Loss [100, 200](epoch, minibatch):  0.405400996953249\n",
            "Loss [100, 300](epoch, minibatch):  0.39841184079647063\n",
            "Loss [101, 100](epoch, minibatch):  0.4078405325114727\n",
            "Loss [101, 200](epoch, minibatch):  0.3955383002758026\n",
            "Loss [101, 300](epoch, minibatch):  0.40446982234716417\n",
            "Loss [102, 100](epoch, minibatch):  0.3967707471549511\n",
            "Loss [102, 200](epoch, minibatch):  0.4022970689833164\n",
            "Loss [102, 300](epoch, minibatch):  0.42518299371004104\n",
            "Loss [103, 100](epoch, minibatch):  0.40306720286607745\n",
            "Loss [103, 200](epoch, minibatch):  0.38913686588406565\n",
            "Loss [103, 300](epoch, minibatch):  0.40814714223146437\n",
            "Loss [104, 100](epoch, minibatch):  0.3776104064285755\n",
            "Loss [104, 200](epoch, minibatch):  0.4016429471969605\n",
            "Loss [104, 300](epoch, minibatch):  0.4029800024628639\n",
            "Loss [105, 100](epoch, minibatch):  0.37802557840943335\n",
            "Loss [105, 200](epoch, minibatch):  0.39569763392210006\n",
            "Loss [105, 300](epoch, minibatch):  0.3959722439944744\n",
            "Loss [106, 100](epoch, minibatch):  0.3795706537365913\n",
            "Loss [106, 200](epoch, minibatch):  0.39395060271024707\n",
            "Loss [106, 300](epoch, minibatch):  0.3876919616758823\n",
            "Loss [107, 100](epoch, minibatch):  0.3867426769435406\n",
            "Loss [107, 200](epoch, minibatch):  0.38162335485219956\n",
            "Loss [107, 300](epoch, minibatch):  0.38965894401073453\n",
            "Loss [108, 100](epoch, minibatch):  0.3849915632605553\n",
            "Loss [108, 200](epoch, minibatch):  0.37250142872333525\n",
            "Loss [108, 300](epoch, minibatch):  0.3877493889629841\n",
            "Loss [109, 100](epoch, minibatch):  0.38434574142098427\n",
            "Loss [109, 200](epoch, minibatch):  0.39908711522817614\n",
            "Loss [109, 300](epoch, minibatch):  0.4020652124285698\n",
            "Loss [110, 100](epoch, minibatch):  0.38001255750656127\n",
            "Loss [110, 200](epoch, minibatch):  0.39136156588792803\n",
            "Loss [110, 300](epoch, minibatch):  0.38627592504024505\n",
            "Loss [111, 100](epoch, minibatch):  0.3595320533216\n",
            "Loss [111, 200](epoch, minibatch):  0.3768394722044468\n",
            "Loss [111, 300](epoch, minibatch):  0.38073748365044596\n",
            "Loss [112, 100](epoch, minibatch):  0.36990217223763466\n",
            "Loss [112, 200](epoch, minibatch):  0.38158498242497446\n",
            "Loss [112, 300](epoch, minibatch):  0.39580864444375036\n",
            "Loss [113, 100](epoch, minibatch):  0.37544468030333517\n",
            "Loss [113, 200](epoch, minibatch):  0.37941751539707186\n",
            "Loss [113, 300](epoch, minibatch):  0.3837523750960827\n",
            "Loss [114, 100](epoch, minibatch):  0.3741243246197701\n",
            "Loss [114, 200](epoch, minibatch):  0.383195726275444\n",
            "Loss [114, 300](epoch, minibatch):  0.38158468082547187\n",
            "Loss [115, 100](epoch, minibatch):  0.35826741993427275\n",
            "Loss [115, 200](epoch, minibatch):  0.36358675673604013\n",
            "Loss [115, 300](epoch, minibatch):  0.3683818519115448\n",
            "Loss [116, 100](epoch, minibatch):  0.3631445018947124\n",
            "Loss [116, 200](epoch, minibatch):  0.3731966307759285\n",
            "Loss [116, 300](epoch, minibatch):  0.3749749726057053\n",
            "Loss [117, 100](epoch, minibatch):  0.35753844112157823\n",
            "Loss [117, 200](epoch, minibatch):  0.3602654093503952\n",
            "Loss [117, 300](epoch, minibatch):  0.3849431720376015\n",
            "Loss [118, 100](epoch, minibatch):  0.36240062832832337\n",
            "Loss [118, 200](epoch, minibatch):  0.36516864016652106\n",
            "Loss [118, 300](epoch, minibatch):  0.3666373306512833\n",
            "Loss [119, 100](epoch, minibatch):  0.3517009106278419\n",
            "Loss [119, 200](epoch, minibatch):  0.3572649109363556\n",
            "Loss [119, 300](epoch, minibatch):  0.3720680114626884\n",
            "Loss [120, 100](epoch, minibatch):  0.3565973950922489\n",
            "Loss [120, 200](epoch, minibatch):  0.37110487803816794\n",
            "Loss [120, 300](epoch, minibatch):  0.36826793253421786\n",
            "Loss [121, 100](epoch, minibatch):  0.35660691529512406\n",
            "Loss [121, 200](epoch, minibatch):  0.3647595205903053\n",
            "Loss [121, 300](epoch, minibatch):  0.3627206587791443\n",
            "Loss [122, 100](epoch, minibatch):  0.35921655982732775\n",
            "Loss [122, 200](epoch, minibatch):  0.35983680933713913\n",
            "Loss [122, 300](epoch, minibatch):  0.3588973000645638\n",
            "Loss [123, 100](epoch, minibatch):  0.3240407785773277\n",
            "Loss [123, 200](epoch, minibatch):  0.36814243465662\n",
            "Loss [123, 300](epoch, minibatch):  0.3776829573512077\n",
            "Loss [124, 100](epoch, minibatch):  0.3535004618763924\n",
            "Loss [124, 200](epoch, minibatch):  0.37304809972643854\n",
            "Loss [124, 300](epoch, minibatch):  0.3616289767622948\n",
            "Loss [125, 100](epoch, minibatch):  0.3480901621282101\n",
            "Loss [125, 200](epoch, minibatch):  0.35881427839398383\n",
            "Loss [125, 300](epoch, minibatch):  0.3603376542031765\n",
            "Loss [126, 100](epoch, minibatch):  0.3470475579798222\n",
            "Loss [126, 200](epoch, minibatch):  0.3510726971924305\n",
            "Loss [126, 300](epoch, minibatch):  0.3445755414664745\n",
            "Loss [127, 100](epoch, minibatch):  0.3474369470775127\n",
            "Loss [127, 200](epoch, minibatch):  0.352577610462904\n",
            "Loss [127, 300](epoch, minibatch):  0.35067463517189024\n",
            "Loss [128, 100](epoch, minibatch):  0.35878952607512477\n",
            "Loss [128, 200](epoch, minibatch):  0.3552806544303894\n",
            "Loss [128, 300](epoch, minibatch):  0.35782360821962356\n",
            "Loss [129, 100](epoch, minibatch):  0.33880246117711066\n",
            "Loss [129, 200](epoch, minibatch):  0.35200429454445836\n",
            "Loss [129, 300](epoch, minibatch):  0.36216071277856826\n",
            "Loss [130, 100](epoch, minibatch):  0.3374209639430046\n",
            "Loss [130, 200](epoch, minibatch):  0.34565437465906146\n",
            "Loss [130, 300](epoch, minibatch):  0.3592541266977787\n",
            "Loss [131, 100](epoch, minibatch):  0.34420315191149714\n",
            "Loss [131, 200](epoch, minibatch):  0.35471836879849433\n",
            "Loss [131, 300](epoch, minibatch):  0.3647485913336277\n",
            "Loss [132, 100](epoch, minibatch):  0.3311212804913521\n",
            "Loss [132, 200](epoch, minibatch):  0.35411637246608735\n",
            "Loss [132, 300](epoch, minibatch):  0.34771510645747183\n",
            "Loss [133, 100](epoch, minibatch):  0.34879650220274927\n",
            "Loss [133, 200](epoch, minibatch):  0.3578437739610672\n",
            "Loss [133, 300](epoch, minibatch):  0.3534333398938179\n",
            "Loss [134, 100](epoch, minibatch):  0.33993049696087835\n",
            "Loss [134, 200](epoch, minibatch):  0.34365585818886757\n",
            "Loss [134, 300](epoch, minibatch):  0.33372333109378816\n",
            "Loss [135, 100](epoch, minibatch):  0.3435570806264877\n",
            "Loss [135, 200](epoch, minibatch):  0.34208935663104056\n",
            "Loss [135, 300](epoch, minibatch):  0.35787161469459533\n",
            "Loss [136, 100](epoch, minibatch):  0.33629267126321793\n",
            "Loss [136, 200](epoch, minibatch):  0.35367766469717027\n",
            "Loss [136, 300](epoch, minibatch):  0.34513500571250916\n",
            "Loss [137, 100](epoch, minibatch):  0.3390709462761879\n",
            "Loss [137, 200](epoch, minibatch):  0.3401822564005852\n",
            "Loss [137, 300](epoch, minibatch):  0.34494010001420977\n",
            "Loss [138, 100](epoch, minibatch):  0.33643126115202904\n",
            "Loss [138, 200](epoch, minibatch):  0.3357292024791241\n",
            "Loss [138, 300](epoch, minibatch):  0.33615485280752183\n",
            "Loss [139, 100](epoch, minibatch):  0.3140544103085995\n",
            "Loss [139, 200](epoch, minibatch):  0.33879277169704436\n",
            "Loss [139, 300](epoch, minibatch):  0.35318807259202\n",
            "Loss [140, 100](epoch, minibatch):  0.3288468973338604\n",
            "Loss [140, 200](epoch, minibatch):  0.3393864466249943\n",
            "Loss [140, 300](epoch, minibatch):  0.3424333757162094\n",
            "Loss [141, 100](epoch, minibatch):  0.32194714307785033\n",
            "Loss [141, 200](epoch, minibatch):  0.3397658702731132\n",
            "Loss [141, 300](epoch, minibatch):  0.339539291113615\n",
            "Loss [142, 100](epoch, minibatch):  0.3347540335357189\n",
            "Loss [142, 200](epoch, minibatch):  0.315582630187273\n",
            "Loss [142, 300](epoch, minibatch):  0.34831397846341133\n",
            "Loss [143, 100](epoch, minibatch):  0.314231574088335\n",
            "Loss [143, 200](epoch, minibatch):  0.33283203676342965\n",
            "Loss [143, 300](epoch, minibatch):  0.3435336697101593\n",
            "Loss [144, 100](epoch, minibatch):  0.3149022310972214\n",
            "Loss [144, 200](epoch, minibatch):  0.32681134551763535\n",
            "Loss [144, 300](epoch, minibatch):  0.33742703452706335\n",
            "Loss [145, 100](epoch, minibatch):  0.31552110210061074\n",
            "Loss [145, 200](epoch, minibatch):  0.32585352927446365\n",
            "Loss [145, 300](epoch, minibatch):  0.36164739713072774\n",
            "Loss [146, 100](epoch, minibatch):  0.3239443518221378\n",
            "Loss [146, 200](epoch, minibatch):  0.3296524353325367\n",
            "Loss [146, 300](epoch, minibatch):  0.3507398754358292\n",
            "Loss [147, 100](epoch, minibatch):  0.33536766439676285\n",
            "Loss [147, 200](epoch, minibatch):  0.3223829904198647\n",
            "Loss [147, 300](epoch, minibatch):  0.3376656912267208\n",
            "Loss [148, 100](epoch, minibatch):  0.31600515529513357\n",
            "Loss [148, 200](epoch, minibatch):  0.32092129364609717\n",
            "Loss [148, 300](epoch, minibatch):  0.34189914211630823\n",
            "Loss [149, 100](epoch, minibatch):  0.3241312074661255\n",
            "Loss [149, 200](epoch, minibatch):  0.3196099989116192\n",
            "Loss [149, 300](epoch, minibatch):  0.3486394253373146\n",
            "Loss [150, 100](epoch, minibatch):  0.3066420157253742\n",
            "Loss [150, 200](epoch, minibatch):  0.3195802411437035\n",
            "Loss [150, 300](epoch, minibatch):  0.3431068998575211\n",
            "Loss [151, 100](epoch, minibatch):  0.33224694669246674\n",
            "Loss [151, 200](epoch, minibatch):  0.3183071739971638\n",
            "Loss [151, 300](epoch, minibatch):  0.3423638492822647\n",
            "Loss [152, 100](epoch, minibatch):  0.34642978832125665\n",
            "Loss [152, 200](epoch, minibatch):  0.3270177839696407\n",
            "Loss [152, 300](epoch, minibatch):  0.3227169094979763\n",
            "Loss [153, 100](epoch, minibatch):  0.307277008742094\n",
            "Loss [153, 200](epoch, minibatch):  0.3271372026205063\n",
            "Loss [153, 300](epoch, minibatch):  0.33797665297985074\n",
            "Loss [154, 100](epoch, minibatch):  0.32206031009554864\n",
            "Loss [154, 200](epoch, minibatch):  0.3303478594124317\n",
            "Loss [154, 300](epoch, minibatch):  0.32448834776878355\n",
            "Loss [155, 100](epoch, minibatch):  0.31449840396642686\n",
            "Loss [155, 200](epoch, minibatch):  0.32796007588505743\n",
            "Loss [155, 300](epoch, minibatch):  0.33130144417285917\n",
            "Loss [156, 100](epoch, minibatch):  0.3113892498612404\n",
            "Loss [156, 200](epoch, minibatch):  0.3227103725075722\n",
            "Loss [156, 300](epoch, minibatch):  0.3235259959101677\n",
            "Loss [157, 100](epoch, minibatch):  0.3148206204175949\n",
            "Loss [157, 200](epoch, minibatch):  0.32804809376597405\n",
            "Loss [157, 300](epoch, minibatch):  0.32944221824407577\n",
            "Loss [158, 100](epoch, minibatch):  0.3153930315375328\n",
            "Loss [158, 200](epoch, minibatch):  0.3190789486467838\n",
            "Loss [158, 300](epoch, minibatch):  0.32482500463724134\n",
            "Loss [159, 100](epoch, minibatch):  0.3094604440033436\n",
            "Loss [159, 200](epoch, minibatch):  0.31802421987056734\n",
            "Loss [159, 300](epoch, minibatch):  0.33602549344301225\n",
            "Loss [160, 100](epoch, minibatch):  0.2985114930570126\n",
            "Loss [160, 200](epoch, minibatch):  0.3151132671535015\n",
            "Loss [160, 300](epoch, minibatch):  0.3287293241918087\n",
            "Loss [161, 100](epoch, minibatch):  0.3192740551382303\n",
            "Loss [161, 200](epoch, minibatch):  0.3229037833213806\n",
            "Loss [161, 300](epoch, minibatch):  0.327662705630064\n",
            "Loss [162, 100](epoch, minibatch):  0.3182452014088631\n",
            "Loss [162, 200](epoch, minibatch):  0.3071175163984299\n",
            "Loss [162, 300](epoch, minibatch):  0.3208728614449501\n",
            "Loss [163, 100](epoch, minibatch):  0.30306683495640757\n",
            "Loss [163, 200](epoch, minibatch):  0.3191795429587364\n",
            "Loss [163, 300](epoch, minibatch):  0.33153048425912857\n",
            "Loss [164, 100](epoch, minibatch):  0.29022287860512735\n",
            "Loss [164, 200](epoch, minibatch):  0.3137145105004311\n",
            "Loss [164, 300](epoch, minibatch):  0.3298540881276131\n",
            "Loss [165, 100](epoch, minibatch):  0.31522508040070535\n",
            "Loss [165, 200](epoch, minibatch):  0.30252447456121445\n",
            "Loss [165, 300](epoch, minibatch):  0.3321299016475677\n",
            "Loss [166, 100](epoch, minibatch):  0.3219172336161137\n",
            "Loss [166, 200](epoch, minibatch):  0.30570544451475146\n",
            "Loss [166, 300](epoch, minibatch):  0.32423094868659974\n",
            "Loss [167, 100](epoch, minibatch):  0.2987763010710478\n",
            "Loss [167, 200](epoch, minibatch):  0.3176428286731243\n",
            "Loss [167, 300](epoch, minibatch):  0.3209958271682262\n",
            "Loss [168, 100](epoch, minibatch):  0.298498168438673\n",
            "Loss [168, 200](epoch, minibatch):  0.32387425377964973\n",
            "Loss [168, 300](epoch, minibatch):  0.315252411365509\n",
            "Loss [169, 100](epoch, minibatch):  0.3010487134754658\n",
            "Loss [169, 200](epoch, minibatch):  0.3111140303313732\n",
            "Loss [169, 300](epoch, minibatch):  0.33768736466765403\n",
            "Loss [170, 100](epoch, minibatch):  0.30396062836050985\n",
            "Loss [170, 200](epoch, minibatch):  0.3120489247143269\n",
            "Loss [170, 300](epoch, minibatch):  0.3163252329826355\n",
            "Loss [171, 100](epoch, minibatch):  0.23135892234742642\n",
            "Loss [171, 200](epoch, minibatch):  0.1839233849942684\n",
            "Loss [171, 300](epoch, minibatch):  0.1749639654159546\n",
            "Loss [172, 100](epoch, minibatch):  0.15314740486443043\n",
            "Loss [172, 200](epoch, minibatch):  0.15375046491622923\n",
            "Loss [172, 300](epoch, minibatch):  0.14663085009902715\n",
            "Loss [173, 100](epoch, minibatch):  0.13515279471874236\n",
            "Loss [173, 200](epoch, minibatch):  0.12577552478760481\n",
            "Loss [173, 300](epoch, minibatch):  0.13073482647538184\n",
            "Loss [174, 100](epoch, minibatch):  0.11289375439286232\n",
            "Loss [174, 200](epoch, minibatch):  0.12025930672883987\n",
            "Loss [174, 300](epoch, minibatch):  0.11613473258912563\n",
            "Loss [175, 100](epoch, minibatch):  0.11220325902104378\n",
            "Loss [175, 200](epoch, minibatch):  0.10915587525814771\n",
            "Loss [175, 300](epoch, minibatch):  0.11114410769194365\n",
            "Loss [176, 100](epoch, minibatch):  0.10735023956745864\n",
            "Loss [176, 200](epoch, minibatch):  0.10142899509519339\n",
            "Loss [176, 300](epoch, minibatch):  0.10648520881310106\n",
            "Loss [177, 100](epoch, minibatch):  0.09288867361843586\n",
            "Loss [177, 200](epoch, minibatch):  0.0982839034497738\n",
            "Loss [177, 300](epoch, minibatch):  0.09825979810208083\n",
            "Loss [178, 100](epoch, minibatch):  0.09750475069507956\n",
            "Loss [178, 200](epoch, minibatch):  0.09152187485247851\n",
            "Loss [178, 300](epoch, minibatch):  0.08786561278626323\n",
            "Loss [179, 100](epoch, minibatch):  0.08975568551570177\n",
            "Loss [179, 200](epoch, minibatch):  0.08916124967858195\n",
            "Loss [179, 300](epoch, minibatch):  0.08701639048755169\n",
            "Loss [180, 100](epoch, minibatch):  0.08157600057311357\n",
            "Loss [180, 200](epoch, minibatch):  0.07788311820477248\n",
            "Loss [180, 300](epoch, minibatch):  0.08907992236316203\n",
            "Loss [181, 100](epoch, minibatch):  0.07977298613637686\n",
            "Loss [181, 200](epoch, minibatch):  0.0790977695863694\n",
            "Loss [181, 300](epoch, minibatch):  0.07999037716537714\n",
            "Loss [182, 100](epoch, minibatch):  0.07117956474423409\n",
            "Loss [182, 200](epoch, minibatch):  0.0764298969693482\n",
            "Loss [182, 300](epoch, minibatch):  0.07589520936831833\n",
            "Loss [183, 100](epoch, minibatch):  0.07125447561964393\n",
            "Loss [183, 200](epoch, minibatch):  0.0730723898112774\n",
            "Loss [183, 300](epoch, minibatch):  0.0728809497319162\n",
            "Loss [184, 100](epoch, minibatch):  0.06854115528054536\n",
            "Loss [184, 200](epoch, minibatch):  0.06877850733697415\n",
            "Loss [184, 300](epoch, minibatch):  0.07029443698003889\n",
            "Loss [185, 100](epoch, minibatch):  0.06611202894710004\n",
            "Loss [185, 200](epoch, minibatch):  0.0649440154992044\n",
            "Loss [185, 300](epoch, minibatch):  0.07324215343687683\n",
            "Loss [186, 100](epoch, minibatch):  0.0663174391631037\n",
            "Loss [186, 200](epoch, minibatch):  0.05825027773156762\n",
            "Loss [186, 300](epoch, minibatch):  0.07000698952935636\n",
            "Loss [187, 100](epoch, minibatch):  0.055343108447268606\n",
            "Loss [187, 200](epoch, minibatch):  0.06364892120938748\n",
            "Loss [187, 300](epoch, minibatch):  0.06684164637699723\n",
            "Loss [188, 100](epoch, minibatch):  0.061228967932984234\n",
            "Loss [188, 200](epoch, minibatch):  0.05958277690224349\n",
            "Loss [188, 300](epoch, minibatch):  0.05676326253451407\n",
            "Loss [189, 100](epoch, minibatch):  0.0611472656391561\n",
            "Loss [189, 200](epoch, minibatch):  0.06490110455080866\n",
            "Loss [189, 300](epoch, minibatch):  0.06048428935930133\n",
            "Loss [190, 100](epoch, minibatch):  0.055132546303793786\n",
            "Loss [190, 200](epoch, minibatch):  0.058940644040703774\n",
            "Loss [190, 300](epoch, minibatch):  0.06363121792674065\n",
            "Loss [191, 100](epoch, minibatch):  0.055160503983497616\n",
            "Loss [191, 200](epoch, minibatch):  0.058047092417255045\n",
            "Loss [191, 300](epoch, minibatch):  0.05879382683895528\n",
            "Loss [192, 100](epoch, minibatch):  0.05978482917882502\n",
            "Loss [192, 200](epoch, minibatch):  0.052418576963245866\n",
            "Loss [192, 300](epoch, minibatch):  0.05760091623291373\n",
            "Loss [193, 100](epoch, minibatch):  0.057579156775027514\n",
            "Loss [193, 200](epoch, minibatch):  0.053032736759632826\n",
            "Loss [193, 300](epoch, minibatch):  0.0515392099134624\n",
            "Loss [194, 100](epoch, minibatch):  0.04858856854960322\n",
            "Loss [194, 200](epoch, minibatch):  0.05079933241941035\n",
            "Loss [194, 300](epoch, minibatch):  0.05227137641049921\n",
            "Loss [195, 100](epoch, minibatch):  0.04953397983685136\n",
            "Loss [195, 200](epoch, minibatch):  0.04823049418162555\n",
            "Loss [195, 300](epoch, minibatch):  0.04794334509875625\n",
            "Loss [196, 100](epoch, minibatch):  0.05127916278317571\n",
            "Loss [196, 200](epoch, minibatch):  0.051455821180716156\n",
            "Loss [196, 300](epoch, minibatch):  0.05200586484279483\n",
            "Loss [197, 100](epoch, minibatch):  0.045989616913720964\n",
            "Loss [197, 200](epoch, minibatch):  0.0495183439925313\n",
            "Loss [197, 300](epoch, minibatch):  0.04817626026459038\n",
            "Loss [198, 100](epoch, minibatch):  0.039967539627104996\n",
            "Loss [198, 200](epoch, minibatch):  0.04799388788640499\n",
            "Loss [198, 300](epoch, minibatch):  0.049513006126508115\n",
            "Loss [199, 100](epoch, minibatch):  0.043269404652528466\n",
            "Loss [199, 200](epoch, minibatch):  0.04019885698333383\n",
            "Loss [199, 300](epoch, minibatch):  0.04475430993828922\n",
            "Loss [200, 100](epoch, minibatch):  0.04401289311703294\n",
            "Loss [200, 200](epoch, minibatch):  0.04519776517525315\n",
            "Loss [200, 300](epoch, minibatch):  0.04484757653903216\n",
            "Training Done\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 200\n",
        "for epoch in range(EPOCHS):\n",
        "    losses = []\n",
        "    running_loss = 0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for i, inp in enumerate(trainloader):\n",
        "        inputs, labels = inp\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i%100 == 0 and i > 0:\n",
        "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
        "            running_loss = 0.0\n",
        "\n",
        "    avg_loss = sum(losses)/len(losses)\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "print('Training Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QqYNJo7rlNyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e93ab1a-ccac-48f3-d7b6-e85a000d70d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on 10,000 test images:  85.9 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print('Accuracy on 10,000 test images: ', 100*(correct/total), '%')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}